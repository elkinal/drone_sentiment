---
title: "Drone Sentiment Analysis"
format: pdf
editor: visual
fig-width: 6
fig-height: 5
---

# Opinions about Drones, sentiment analysis

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r}
#| label: libraries

# Basic
library(tidyverse)
library(scales)
library(knitr)

# For cleaning / filtering text
library(stringr)
library(wordcloud)
library(tm)
library(janeaustenr)
library(textstem)
library(syuzhet)
library(sentimentr)

# For rendering
library(rmarkdown)
library(stringr)
library(gridExtra)
library(grid)

```

```{r}
#| label: tidying-data

data1 <- read_csv("data/data1.csv")
 
# The number of total responses
pre_length = nrow(data1)

# Filtering and cleaning responses
response <- data1 |>
  select(Q6, Q8) |>
  rename(
    reason = Q6, # text
    opinion = Q8 # number
  )|>
  mutate(reason = gsub("(\n|<br />)"," ",reason)) |> 
  mutate(reason = gsub("'","",reason)) |>
  mutate(reason = gsub("â€™","",reason)) |>
  mutate(reason = gsub(".","",reason, fixed = TRUE)) |> #prevent sentence splitting
  mutate(reason = gsub("?","",reason, fixed = TRUE)) |> #prevent sentence splitting
  mutate(reason = gsub("!","",reason, fixed = TRUE)) |> #prevent sentence splitting
  drop_na() 
  


# Removing first 2 rows
response = response[-c(1, 2),]

# Reformatting opinion column
response$opinion = as.numeric(response$opinion)

# Lemmatizing words - reducing them to base form
lemmatize <- function(sentence) {
  return(paste(lemmatize_words(strsplit(sentence, " ")[[1]]),
        collapse=" "))
}
response[c("reason")] <- apply(response[c("reason")], 1,lemmatize)


# Adding sentence-level sentiments to each response
#response |>
#  mutate(sentiment = sentiment(reason)$sentiment) 

# Function to turn a column into a corpus
create_corpus <- function(column) {
  
  # Creating Corpus for ALL RAW REASONS
  corpus <- VCorpus(
    VectorSource(
      as.vector(column))
    )
  
  corpus <- corpus |>
    tm_map(removeNumbers) |>
    tm_map(removePunctuation) |>
    tm_map(stripWhitespace) 
    
  corpus <- tm_map(corpus, content_transformer(tolower)) 
  corpus <- tm_map(corpus, removeWords, stopwords("english"))
  
  return (corpus)
}

# Corpus for all REASONS 
q6_corpus = create_corpus(response$reason)


# Creating Corpus for OPINIONS & REASONS
reason_list <- split(response, response$opinion)
opinion_corpus_list <- list()


# Corpuses for the REASONS, split per OPINION (1-5)
opinion_1_corpus = create_corpus(reason_list[[1]]$reason)
opinion_2_corpus = create_corpus(reason_list[[2]]$reason)
opinion_3_corpus = create_corpus(reason_list[[3]]$reason)
opinion_4_corpus = create_corpus(reason_list[[4]]$reason)
opinion_5_corpus = create_corpus(reason_list[[5]]$reason)

# Corpuses for the REASONS, split by GENERAL OPINION 
# where scores of 1 or 2 = oppose & 4 or 5 = support


# Creating corpuses for general support / opposition
opinion_support_corpus = create_corpus(
  rbind(reason_list[[1]], reason_list[[2]])$reason
)

opinion_oppose_corpus = create_corpus(
  rbind(reason_list[[4]], reason_list[[5]])$reason
)

# Calculating the number of real responses
post_length = nrow(response)
yield = round(((post_length / pre_length) * 100), 3)

#response
```

The data has `r pre_length` responses. The percentage of non-blank responses is `r yield` %

```{r}
#| label: word-ratio

# Returns a word-frequency matrix from a corpus
get_wfm <- function(corpus) {
  dtm <- TermDocumentMatrix(corpus) 
  matrix <- as.matrix(dtm) 
  words <- sort(rowSums(matrix),decreasing=TRUE) 
  wfm <- data.frame(word = names(words),freq=words)
  
  return (wfm)
}


# Draws the word-frequency graph between 2 corpuses
draw_wfm_diff_graph <- function(corpus_1, corpus_2, n_width, p_width) {
  
  # Creating word-frequency matrix
  opinion_1_wfm = get_wfm(corpus_1)
  opinion_5_wfm = get_wfm(corpus_2)
  
  # Adding negative sign to opposing views
  opinion_1_wfm <- opinion_1_wfm |>
    mutate(freq = -freq)
  
  # Calculating the relative frequencies
  opinion_1_wfm <- opinion_1_wfm |>
    mutate(ratio = freq / (nrow(opinion_1_wfm)))
  
  opinion_5_wfm <- opinion_5_wfm |>
    mutate(ratio = freq / (nrow(opinion_5_wfm)))
  
  # Finding the difference in word frequencies
  opinion_diff <- rbind(opinion_1_wfm, opinion_5_wfm)
  opinion_diff <- opinion_diff |>
    group_by(word) |>
    summarize(diff_freq = sum(ratio)) |>
    arrange(desc(diff_freq))
  
  # Joining the most significant words
  largest_diff <- rbind(head(opinion_diff, p_width), tail(opinion_diff, n_width))
  
  
  # Drawing the grap
  largest_diff |>
    ggplot(
      aes(reorder(word, -diff_freq, sum), 
          diff_freq, fill = diff_freq < 0)) + 
    
    geom_bar(stat="identity") +
    
    coord_flip() +  
    ylab("Difference in word frequency") + 
    xlab("Word") +
    ggtitle("Word frequency of drone export supporters / opposers") + 
    
    scale_fill_manual(
      values=c("#77dd76", "#f69185"),
      name="Drone export\nopinion",
                           breaks=c("FALSE", "TRUE"),
                           labels=c("Support", "Oppose")) +
    
    
    ylim(-0.1,0.09) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 2)) 
}

draw_wfm_diff_graph(opinion_support_corpus, opinion_oppose_corpus, 15, 15)


```

The difference in word frequency represents the percentage of the difference between the words used. For example, "good" is featured 8% more frequently in supportive votes than in opposing ones. On the other hand, "war" and "weapon" are featured more frequently in opposing votes.

The reason the word frequencies for supporters peak much more than for people opposing drone exports is because opposing viewpoints tended to use a greater variety of language, whereas drone export supporters mostly used the same words like "good", "country" and "ally".

```{r}

draw_wfm_diff_graph(opinion_support_corpus, opinion_oppose_corpus, 30, 0)
```

A closer analysis at the comments of the people opposing drone exports shows many of the factors people are concerned about.

```{r}

draw_wfm_diff_graph(opinion_support_corpus, opinion_oppose_corpus, 0, 30)
```

Similarly, looking at the comments by the people supporting drone exports reveals the reasoning behind their opinions.

```{r}
#| label: generate-wordcloud

# Draws a Word Cloud based from a corpus
generate_wordcloud <- function(corpus) {
  wfm <- get_wfm(corpus)
  wfm <- wfm[c(-1, -2),] # removing the words "drone" and "country"
  set.seed(1234) 
  wordcloud(words = wfm$word, 
            freq = wfm$freq, 
            min.freq = 1,           
            max.words=200, 
            random.order=FALSE, 
            rot.per=0.35,            
            colors=brewer.pal(8, "Dark2"))
}
```

```{r}
#| label: strong-support-wordcloud

# Drawing worldcloud for STRONG OPPOSITION (1)
generate_wordcloud(opinion_1_corpus)
```

A word cloud of words used by people who voted (1), "Strongly Opposing" drone exports.

```{r}
#| label: strong-opposition-worldcloud

# Drawing worldcloud for STRONG SUPPORT (5)
generate_wordcloud(opinion_5_corpus)
```

A word cloud of words used by people who voted (5), "Strongly Supporting" drone exports.

#### 10 Most Positive responses

```{r}

score_responses <- response |>
  mutate(score = get_sentiment(reason)) |>
  arrange(score) 


head(score_responses, 10) |>
  select(reason, score)
```

#### 10 Most Negative responses

```{r}
tail(score_responses, 10) |>
  select(reason, score)
```

This shows the most positive and negative arguments for drone exports to foreign exports.

```{r}

# Adds line breaks to text
prnt.test <- function(x){
   cat(x, sep="\n\n")
}

# Adds comma flags to text
break_words <- function(startstring) {
  words = strsplit(startstring, ' ')[[1L]]
  splits = cut(seq_along(words), breaks = seq(0L, length(words) + 12L, by = 12L))
  paste(lapply(split(words, splits), paste, collapse = ' '), collapse = '\n')
}

# Prints everything with line breaks every 12 words.
prnt_all_multi <- function(neg_lst) {
  for (x in 1:nrow(neg_lst)) {
    print(sprintf("[Response %s]", x))
    writeLines(break_words(neg_lst$reason[[x]]))  
    writeLines("\n")
  }
}

```

The full text for the 10 most **positive** responses is below.

```{r}

prnt_all_multi(neg_lst = tail(score_responses, 10) |>
              select(reason))
```

Similarly, the 10 most **negative** responses are here:

```{r}

prnt_all_multi(neg_lst = head(score_responses, 10) |>
              select(reason))
```

Note that these responses have grammatical issues because all the words have been reduced to their base form, and all their punctuation has been removed.
