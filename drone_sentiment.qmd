---
title: "Drone Sentiment Analysis"
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

```{r}

# Basic
library(tidyverse)
library(scales)
library(stringr)

# For cleaning / filtering text
library(wordcloud)
library(tm)
library(janeaustenr)

# For rendering
library(rmarkdown)
library(stringr)

```

```{r}
#| label: filtering

data1 <- read_csv("data/data1.csv")
 
# The number of total responses
pre_length = nrow(data1)

# Filtering and cleaning
response <- data1 |>
  select(Q6, Q8) |>
  rename(
    reason = Q6,
    opinion = Q8
  )|>
  mutate(opinion = gsub("(\n|<br />)"," ",opinion)) |>
  drop_na() 

# Removing first 2 rows
response = response[-c(1, 2),]

# Reformatting opinion column
response$opinion = as.numeric(response$opinion)

# Function turns a column into a corpus
create_corpus <- function(column) {
  
  # Creating Corpus for ALL RAW REASONS
  corpus <- VCorpus(
    VectorSource(
      as.vector(column))
    )
  
  corpus <- corpus |>
    tm_map(removeNumbers) |>
    tm_map(removePunctuation) |>
    tm_map(stripWhitespace) 
    
  corpus <- tm_map(corpus, content_transformer(tolower)) 
  corpus <- tm_map(corpus, removeWords, stopwords("english"))
  
  return (corpus)
}

# Corpus for all REASONS 
q6_corpus = create_corpus(response$reason)


# Creating Corpus for OPINIONS & REASONS
reason_list <- split(response, response$opinion)
opinion_corpus_list <- list()


# Corpuses for the REASONS, split per OPINION (1-5)
opinion_1_corpus = create_corpus(reason_list[[1]]$reason)
opinion_2_corpus = create_corpus(reason_list[[2]]$reason)
opinion_3_corpus = create_corpus(reason_list[[3]]$reason)
opinion_4_corpus = create_corpus(reason_list[[4]]$reason)
opinion_5_corpus = create_corpus(reason_list[[5]]$reason)


# Calculating the number of real responses
post_length = nrow(response)
yield = round(((post_length / pre_length) * 100), 3)


```

The data has `r pre_length` responses. The percentage of non-blank responses is `r yield` %

```{r}
#| label: q6-wordcloud



# Returns a word-frequency matrix from a corpus
get_wfm <- function(corpus) {
  dtm <- TermDocumentMatrix(corpus) 
  matrix <- as.matrix(dtm) 
  words <- sort(rowSums(matrix),decreasing=TRUE) 
  wfm <- data.frame(word = names(words),freq=words)
  
  return (wfm)
}

# Draws a Word Cloud based from a corpus
generate_wordcloud <- function(corpus) {

  wfm <- get_wfm(corpus)
  
  set.seed(1234) 
  
  wordcloud(words = wfm$word, 
            freq = wfm$freq, 
            min.freq = 1,           
            max.words=200, 
            random.order=FALSE, 
            rot.per=0.35,            
            colors=brewer.pal(8, "Dark2"))
}



#generate_wordcloud(q6_corpus)

generate_wordcloud(opinion_1_corpus)



draw_wfm_diff_graph <- function(corpus_1, corpus_2) {
    
  
  
  opinion_1_wfm = get_wfm(corpus_1)
  opinion_5_wfm = get_wfm(corpus_2)
  
  
  opinion_1_wfm
  opinion_5_wfm
  
  
  
  #ln 0 is undefined
  
  # adding negative sign
  opinion_1_wfm <- opinion_1_wfm |>
    mutate(freq = -freq)
  
  
  # Calculating the relative frequencies
  opinion_1_wfm <- opinion_1_wfm |>
    mutate(ratio = freq / (nrow(opinion_1_wfm)))
  
  opinion_5_wfm <- opinion_5_wfm |>
    mutate(ratio = freq / (nrow(opinion_5_wfm)))
  
  
  
  # Finding the difference in word frequencies
  opinion_diff <- rbind(opinion_1_wfm, opinion_5_wfm)
  opinion_diff <- opinion_diff |>
    group_by(word) |>
    summarize(diff_freq = sum(ratio)) |>
    arrange(desc(diff_freq))
  
  
  # HOW much more likely is 1 to use w than 5
    # TOP 15 words used by 1 and 5
  
  # the difference in between the ratios
  # logratio
  
  largest_diff <- rbind(head(opinion_diff, 15), tail(opinion_diff, 15))
  
  largest_diff
  
  largest_diff |>
    ggplot(aes(reorder(word, -diff_freq, sum), diff_freq, fill = diff_freq < 0)) + 
    geom_bar(stat="identity") +
    
    coord_flip() +
  #  ylim(-0.04, 0.04)
    
    ylab("Difference in word frequency") +
    xlab("Word") +
    
    ggtitle("Word frequency of drone export supporters / opposers") + 
    
    
    scale_fill_manual(
      values=c("#77dd76", "#f69185"),
      name="Drone export\nopinion",
                           breaks=c("FALSE", "TRUE"),
                           labels=c("Support", "Oppose"))
}


draw_wfm_diff_graph(opinion_1_corpus, opinion_5_corpus)

# WORDS represent the difference in the ratio of words that have been used.
# for example, almost 0.04 , 4% of words used by suppoters is "good"

#BETWEEN strongly agree and disagree, what about other options?

# MAKE this into a function and do this BY country
  
  # ADD a neutral opinion?

```

```{r}

generate_wordcloud(opinion_5_corpus)
```

Pending Sarah's feedback, here's what I'd like you to do this week to close out this task:

     - First, send me an image of the WordCloud for word frequency; I cannot view it presently.

     - Second, complete positive and negative sentiment on drone exports, and by country.

     - Third, build a table or figure that presents key findings by support, positive and negative sentiment, and by country. For example, columns could be the dv - support, +/- sentiment, country - and rows could be word associations at prescribed corlimits. BTW, why did you choose the corlimits you did?

     - Fourth, write two paragraphs, one on the sentiment analysis method and one on the key findings, integrating results by support, positive and negative sentiment, and by country. 

```{r}
#| label: sentiment

# http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know

# https://uc-r.github.io/sentiment_analysis

#wfm

# TODO:

# Wordcloud by support
# q8 To what extent do you agree that U.S. officials have a moral obligation to sell U.S.-manufactured drones to allies and partners?




# Words associated with "Ukraine"
findAssocs(dtm, terms = "ukraine", corlimit = 0.18)

# Words associaed with "support"
findAssocs(dtm, terms = "support", corlimit = 0.14)

# Words associaed with "drone"
findAssocs(dtm, terms = "drone", corlimit = 0.2)

# Words associaed with "innocent"
findAssocs(dtm, terms = "innocent", corlimit = 0.5)






# The goal is to find out WHY people support certain viewpoints.
# what are they motivated by -> what emotions does their text exhibit 
# -> use emotion sentiment analysis library...? alternatives? need time.

```
